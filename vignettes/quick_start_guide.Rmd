---
title: "Quick start guide"
author: "Martin Westgate"
date: '2024-12-12'
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick start guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

`galaxias` is an R package to help users build repositories that are optimised
for storing, documenting and sharing biodiversity data. These repositories can 
be seamlessly converted into a **Darwin Core Archive**, the data standard used 
by the [Global Biodiversity Information Facility (GBIF)](https://gbif.org) and
its partner nodes.

```{r, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
# load packages now to avoid messages later
library(galaxias)
library(lubridate)
library(dplyr)
```

Here we have an existing R project with data we already collected as part of 
an existing research project. Our existing project looks like this:

```{r, eval=TRUE, echo=FALSE}
devtools::load_all()
```

```
├── README.md                        : Description of the repository
├── my-project-name.Rproj            : RStudio project file
├── data-raw                         : Folder to store original/source data
└── data                             : Folder to store cleaned data
└── scripts                          : Folder with analytic coding scripts
└── plots                            : Folder containing plots/dataviz
```

This is a fairly standard project folder structure, containing elements of a 
complete analytic workflow. Let's see how galaxias helps us to prepare our 
data as a Darwin Core Archive.


## Use standardised data in an archive

Our data that we wish to share in the `data` folder looks something like this.

```{r}
#| echo: false
#| message: false
#| warning: false
library(galaxias)
library(tibble)

my_data <- tibble(
  latitude = c(-35.310, -35.273),
  longitude = c(149.125, 149.133),
  date = c("14-01-2023", "15-01-2023"),
  time = c("10:23", "11:25"),
  species = c("Callocephalon fimbriatum", "Eolophus roseicapilla")
  )

my_data
```

We can standardise our data to use Darwin Core Standard using `set_` functions 
(imported from the [corella package](https://corella.ala.org.au/) 
automatically loaded with galaxias). 

`set_` functions work a lot like 
`dplyr::mutate()`; use them to modify and create columns. 
`set_` function names suggest the type of data they accept, and arguments are valid Darwin Core terms to use as column names. In addition, each `set_` function checks to make sure that each column contains valid data according to Darwin Core Standard.

A good place to start standardising our data is to use `suggest_workflow()` which will summarise the steps to preparing our data for a Darwin Core Archive.

```{r}
#| collapse: true
#| comment: "#>"

my_data |> suggest_workflow()
```

Following the advice of `suggest_workflow()` output, we can use `set_` functions 
to standardise `my_data`.

```{r}
#| echo: true
#| eval: false
library(lubridate)

occurrences <- df |>
  # basic requirements of Darwin Core
  set_occurrences(occurrenceID = sequential_id(),
                  basisOfRecord = "humanObservation") |> 
  # place and time
  set_coordinates(decimalLatitude = latitude, 
                  decimalLongitude = longitude) |>
  set_locality(country = "Australia", 
               locality = "Canberra") |>
  set_datetime(eventDate = lubridate::dmy(date),
               eventTime = lubridate::hm(time)) |>
  # taxonomy
  set_scientific_name(scientificName = species, 
                      taxonRank = "species") |>
  set_taxonomy(kingdom = "Animalia", 
               phylum = "Aves") 

occurrences |> print(n = 5)
```

```{r}
#| echo: false
#| message: false
#| collapse: true
#| comment: "#>"
library(lubridate)

occurrences <- my_tbl |>
  # basic requirements of Darwin Core
  set_occurrences(occurrenceID = sequential_id(),
                  basisOfRecord = "humanObservation") |> 
  # place and time
  set_coordinates(decimalLatitude = latitude, 
                  decimalLongitude = longitude) |>
  set_locality(country = "Australia", 
               locality = "Canberra") |>
  set_datetime(eventDate = lubridate::dmy(date),
               eventTime = lubridate::hm(time)) |>
  # taxonomy
  set_scientific_name(scientificName = species, 
                      taxonRank = "species") |>
  set_taxonomy(kingdom = "Animalia",
               phylum = "Aves") 

occurrences |> print(n = 5)
```

Notice that we added several additional columns with more information to our 
data (`country`, `locality`, `taxonRank`, `kingdom`, `phylum`). We encourage 
users to specify additional information to avoid ambiguity once their data 
are shared.

To use our standardised data in a Darwin Core Archive, we can select accepted columns in an 
Occurrence-based dataset, as invalid columns won't be accepted when we build our 
Darwin Core Archive. Accepted Darwin Core terms for Occurrence-based data 
are saved in `occurrence_terms()`. 

```{r}
#| warning: false
#| message: false
library(dplyr)

occurrences_filtered <- occurrences |>
  select(any_of(occurrence_terms()))

occurrences_filtered
```

Now we can specify that `occurrences_filtered` is the data we wish to use in our 
final Darwin Core Archive. `galaxias::use_data()` saves this data in the 
`data_publish` folder.

```{r}
#| eval: false
library(readr)
occurrences_filtered |> 
  galaxias::use_data()
```

You can then use `build_schema()` to create a 'schema'
file, which is an `xml` document that tells users what data is present in your 
archive.

## Adding metadata

A critical part of a Darwin Core archive is a metadata statement; this tells 
users who owns the data, what the data were collected for, and what uses they
can be put to (i.e. a data licence). To get an example statement, call
`use_metadata_template()`

```{r, eval=FALSE}
use_metadata_template()
```

This creates a blank statement called 'metadata.Rmd', which looks like this:

```{r, echo=FALSE, eval=FALSE}
# this code doesn't work any more
# best practice here might be to call `use_metadata()` then `readLines()` and `cat()`
library(delma)
metadata_string <- as_eml_chr(metadata_example)[3:15]
  metadata_string |>
  paste0("\n") |>
  cat()
```

We can edit the statement to reflect the information we wish to 
convey about our data. Once our metadata statement is complete, we can use it in 
our Darwin Core Archive with `use_metadata()`. This converts our 
markdown metadata statement to Ecological Meta Language (`EML`), the accepted 
format of metadata for Darwin Core Archives.

```{r, eval=FALSE}
galaxias::use_metadata()
```

## Build an archive

At the end of the above process, you should have a folder named `data-publish` that 
contains at least two files:

- One or more `.csv` files containing data (e.g. `occurrences.csv`)
- An `eml.xml` file containing your metadata

If that is true, then you can run `build_archive()` to zip your data into a 
Darwin Core Archive:

```{r eval=FALSE}
build_archive()
```


## START HERE
`build_archive()` will begin by constructing a **schema**, a required file that 
provides information about the data's structure. 
- A `meta.xml` file containing your schema


#### schema
A second piece of metadata required by the Darwin Core standard is the 'schema'
document. This is a machine-readable `xml` document that describes the content
of the archive's data files. You can generate one using:

```{r, eval=FALSE}
build_schema()
```

#### Start with a project

```{r, eval=FALSE}
library(galaxias)
galaxias_project("my-project-name")
```

If you are using RStudio, this should launch a new RStudio instance for
that project, which will have the following structure:

```
├── README.md                        : Description of the repository
├── metadata.Rmd                     : Boilerplate metadata statement for this project
├── my-project-name.Rproj            : RStudio project file
├── data-raw                         : Folder to store source data
└── data                             : Folder to store processed data
```

It is a good idea to write some basic information in your `README.Rmd` file
first, as this provides guidance to your users as to what your package contains,
as well as what they are allowed to use it for.
