[{"path":"https://galaxias.ala.org.au/articles/events-example.html","id":"the-dataset","dir":"Articles","previous_headings":"","what":"The dataset","title":"Standardise an Events dataset","text":"example, ’ll use sample dataset containing observations frogs. Data collected using 5-minute audio surveys, row records whether frog species detected within 5-minute audio recording, recorded present (1) absent (0). First, let’s view list eight frog species recorded dataset. abbreviation column contains abbreviated column name used observational dataset. Now let’s view observational dataset. data contains columns describe site location (e.g. site_code, water_type, veg_canopy) columns containing data whether frog species present absent sample (e.g. cpar, csig, limdum). :::{.panel-tabset}","code":"library(readxl) library(dplyr) library(tidyr)  species <- read_xlsx(\"Frogwatch_dataset.xlsx\",                       sheet = \"species list\") |>    janitor::clean_names()  species ## # A tibble: 8 × 3 ##   scientific_name            common_name            abbreviation ##   <chr>                      <chr>                  <chr>        ## 1 Crinia parinsignifera      Plains Froglet         cpar         ## 2 Crinia signifera           Common Eastern Froglet csig         ## 3 Limnodynastes dumerilii    Pobblebonk             limdum       ## 4 Limnodynastes peronii      Striped Marsh Frog     limper       ## 5 Limnodynastes tasmaniensis Spotted Grass Frog     limtas       ## 6 Litoria peronii            Emerald Spotted Frog   lper         ## 7 Litoria verreauxii         Alpine Tree Frog       lver         ## 8 Uperoleia laevigata        Smooth Toadlet         ulae obs <- read_xlsx(\"Frogwatch_dataset.xlsx\",                   sheet = \"observations\") |>   janitor::clean_names()"},{"path":"https://galaxias.ala.org.au/articles/events-example.html","id":"glimpse","dir":"Articles","previous_headings":"","what":"Glimpse","title":"Standardise an Events dataset","text":"","code":"obs |> tibble::glimpse() ## Rows: 3,633 ## Columns: 18 ## $ site_code  <chr> \"AMA100\", \"AMA100\", \"AMA100\", \"AMA100\", \"AMA100\", \"AMA100\",… ## $ year       <dbl> 2004, 2007, 2007, 2005, 2008, 2008, 2013, 2008, 2013, 2014,… ## $ depth      <chr> \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"de… ## $ water_type <chr> \"moving\", \"moving\", \"moving\", \"moving\", \"moving\", \"moving\",… ## $ log_size   <dbl> 2.9145355, 2.9145355, 2.9145355, 2.9145355, 2.9145355, 2.91… ## $ veg_aqu    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,… ## $ veg_canopy <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ veg_bank   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,… ## $ pc_urban   <dbl> 0.2260, 0.2067, 0.2067, 0.2813, 0.2067, 0.2067, 0.2200, 0.2… ## $ pc_canopy  <dbl> 0.0427, 0.0987, 0.0987, 0.0567, 0.0607, 0.0607, 0.0860, 0.0… ## $ cpar       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ csig       <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ limdum     <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ limper     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,… ## $ limtas     <dbl> 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ lper       <dbl> 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ lver       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ ulae       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…"},{"path":"https://galaxias.ala.org.au/articles/events-example.html","id":"sample","dir":"Articles","previous_headings":"","what":"Sample","title":"Standardise an Events dataset","text":"::: observational dataset wide format. row represents one sample, containing multiple observations. Darwin Core Archive, require data long format, row contains one observation. Let’s make adjustment added hierarchical structure data collection (ie Site -> Sample -> Occurrence) adds richness ecological data. Events data can also allow recording presences absences data, enables nuanced probabilistic analyses like species distribution models occupancy models.","code":"obs |>    print(n = 8) |>   rmarkdown::paged_table() ## # A tibble: 3,633 × 18 ##   site_code  year depth water_type log_size veg_aqu veg_canopy veg_bank pc_urban ##   <chr>     <dbl> <chr> <chr>         <dbl>   <dbl>      <dbl>    <dbl>    <dbl> ## 1 AMA100     2004 deep  moving         2.91       1          0        1    0.226 ## 2 AMA100     2007 deep  moving         2.91       1          0        1    0.207 ## 3 AMA100     2007 deep  moving         2.91       1          0        1    0.207 ## 4 AMA100     2005 deep  moving         2.91       1          0        1    0.281 ## 5 AMA100     2008 deep  moving         2.91       1          0        1    0.207 ## 6 AMA100     2008 deep  moving         2.91       1          0        1    0.207 ## 7 AMA100     2013 deep  moving         2.91       1          0        1    0.22  ## 8 AMA100     2008 deep  moving         2.91       1          0        1    0.207 ## # ℹ 3,625 more rows ## # ℹ 9 more variables: pc_canopy <dbl>, cpar <dbl>, csig <dbl>, limdum <dbl>, ## #   limper <dbl>, limtas <dbl>, lper <dbl>, lver <dbl>, ulae <dbl> obs |>   select(site_code, any_of(species$abbreviation)) |>   pivot_longer(cols = species$abbreviation,                names_to = \"abbreviation\") |>   left_join(species, by = \"abbreviation\", keep = FALSE) |>   select(-abbreviation) |>   relocate(value, .after = last_col()) ## # A tibble: 29,064 × 4 ##    site_code scientific_name            common_name            value ##    <chr>     <chr>                      <chr>                  <dbl> ##  1 AMA100    Crinia parinsignifera      Plains Froglet             1 ##  2 AMA100    Crinia signifera           Common Eastern Froglet     0 ##  3 AMA100    Limnodynastes dumerilii    Pobblebonk                 0 ##  4 AMA100    Limnodynastes peronii      Striped Marsh Frog         0 ##  5 AMA100    Limnodynastes tasmaniensis Spotted Grass Frog         1 ##  6 AMA100    Litoria peronii            Emerald Spotted Frog       1 ##  7 AMA100    Litoria verreauxii         Alpine Tree Frog           0 ##  8 AMA100    Uperoleia laevigata        Smooth Toadlet             0 ##  9 AMA100    Crinia parinsignifera      Plains Froglet             1 ## 10 AMA100    Crinia signifera           Common Eastern Froglet     0 ## # ℹ 29,054 more rows sites <- read_xlsx(\"Frogwatch_dataset.xlsx\",                     sheet = \"sites\") |>   janitor::clean_names()"},{"path":"https://galaxias.ala.org.au/articles/occurrences-example.html","id":"the-dataset","dir":"Articles","previous_headings":"","what":"The dataset","title":"Standardise an Occurrences dataset","text":"Let’s use small example dataset bird observations taken 4 different site locations. dataset many different types data like landscape type age class. Importantly standardising Darwin Core, dataset contains scientific name (species), coordinate location (lat & lon) date observation (date).","code":"library(galaxias) library(dplyr) library(readxl)  obs <- read_xlsx(\"dummy-dataset-sb.xlsx\",                  sheet = 1) |>   janitor::clean_names()  obs |>    gt::gt() |>   gt::opt_interactive(page_size_default = 5)"},{"path":"https://galaxias.ala.org.au/articles/occurrences-example.html","id":"standardise-to-darwin-core","dir":"Articles","previous_headings":"","what":"Standardise to Darwin Core","title":"Standardise an Occurrences dataset","text":"determine need standardise dataset, let’s use suggest_workflow(). output tells us one matching Darwin Core term data already (sex), missing minimum required Darwin Core terms. “Suggest workflow”, output suggests series piped set_ functions can use rename, modify add columns missing obs required Darwin Core. set_ functions specialised wrappers around dplyr::mutate(), additional functionality support using Darwin Core Standard. simplicity, let’s easy part first renaming columns already dataset use accepted standard Darwin Core terms. set_ functions automatically check make sure column correctly formatted. ’ll save modified dataframe obs_dwc. Running suggest_workflow() reflect progress show us ’s left . Now output tells us still need add several columns dataset meet minimum Darwin Core requirements. ’s rundown columns need add: occurrenceID: Unique identifiers record. ensures can identify specific record future updates corrections. can use composite_id(), sequential_id() random_id() add unique IDs row. basisOfRecord: type record (e.g. human observation, specimen, machine observation). See list acceptable values corella::basisOfRecord_values(). geodeticDatum: Coordinate Reference System (CRS) projection data (example, CRS Google Maps “WGS84”). coordinateUncertaintyInMeters: area uncertainty around observation. may know value based method data collection Now let’s add columns using set_occurrences() set_coordinates(). can also add suggested function set_individual_traits() automatically identify matched column name sex check column’s format. Running suggest_workflow() confirm dataset ready used Darwin Core Archive! submit dataset, let’s select columns valid occurrence term names save dataframe file occurrences.csv. Importantly, save csv folder called data-processed, galaxias looks automatically building Darwin Core Archive. done! See Quick start guide vignette build Darwin Core Archive.","code":"obs |>   suggest_workflow() #>  #> ── Matching Darwin Core terms ────────────────────────────────────────────────── #> Matched 1 of 12 column names to DwC terms: #> ✔ Matched: sex #> ✖ Unmatched: age_class, comments, date, landscape, lat, lon, molecular_sex, #>   sample_id, site, species, species_code #>  #> ── Minimum required Darwin Core terms ────────────────────────────────────────── #>  #>   Type                      Matched term(s)  Missing term(s)                                                                 #> ✖ Identifier (at least one) -                occurrenceID, catalogNumber, recordNumber                                        #> ✖ Record type               -                basisOfRecord                                                                    #> ✖ Scientific name           -                scientificName                                                                   #> ✖ Location                  -                decimalLatitude, decimalLongitude, geodeticDatum, coordinateUncertaintyInMeters  #> ✖ Date/Time                 -                eventDate #>  #> ── Suggested workflow ────────────────────────────────────────────────────────── #>  #> To make your data Darwin Core compliant, use the following workflow: #>  #> df |> #>   set_occurrences() |> #>   set_datetime() |> #>   set_coordinates() |> #>   set_scientific_name() #>  #> ── Additional functions #> Based on your matched terms, you can also add to your pipe: #> • `set_individual_traits()` #> ℹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms obs_dwc <- obs |>   set_scientific_name(scientificName = species) |>   set_coordinates(decimalLatitude = lat,                   decimalLongitude = lon) |>   set_datetime(eventDate = lubridate::ymd(date)) # specify year-month-day format #> ⠙ Checking 1 column: scientificName #> ⠹ Checking 1 column: scientificName #> ✔ Checking 1 column: scientificName [327ms] #>  #> ⠙ Checking 2 columns: decimalLatitude and decimalLongitude #> ✔ Checking 2 columns: decimalLatitude and decimalLongitude [618ms] #>  #> ⠙ Checking 1 column: eventDate #> ✔ Checking 1 column: eventDate [311ms] #> obs_dwc |>   suggest_workflow() #>  #> ── Matching Darwin Core terms ────────────────────────────────────────────────── #> Matched 5 of 12 column names to DwC terms: #> ✔ Matched: decimalLatitude, decimalLongitude, eventDate, scientificName, sex #> ✖ Unmatched: age_class, comments, landscape, molecular_sex, sample_id, site, #>   species_code #>  #> ── Minimum required Darwin Core terms ────────────────────────────────────────── #>  #>   Type                      Matched term(s)                  Missing term(s)                             #> ✔ Scientific name           scientificName                   -                                            #> ✔ Date/Time                 eventDate                        -                                            #> ✖ Identifier (at least one) -                                occurrenceID, catalogNumber, recordNumber    #> ✖ Record type               -                                basisOfRecord                                #> ✖ Location                  decimalLatitude decimalLongitude geodeticDatum coordinateUncertaintyInMeters #>  #> ── Suggested workflow ────────────────────────────────────────────────────────── #>  #> To make your data Darwin Core compliant, use the following workflow: #>  #> df |> #>   set_occurrences() |> #>   set_coordinates() #>  #> ── Additional functions #> Based on your matched terms, you can also add to your pipe: #> • `set_individual_traits()` #> ℹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms obs_dwc <- obs_dwc |>   set_occurrences(     occurrenceID = composite_id(sequential_id(), site, landscape),     basisOfRecord = \"humanObservation\"     ) |>   set_coordinates(     geodeticDatum = \"WGS84\",     coordinateUncertaintyInMeters = 30     # coordinateUncertaintyInMeters = with_uncertainty(method = \"phone\")     ) |>   set_individual_traits() #> ⠙ Checking 2 columns: occurrenceID and basisOfRecord #> ✔ Checking 2 columns: occurrenceID and basisOfRecord [619ms] #>  #> ⠙ Checking 4 columns: decimalLatitude, decimalLongitude, coordinateUncertaintyI… #> ⠹ Checking 4 columns: decimalLatitude, decimalLongitude, coordinateUncertaintyI… #> ✔ Checking 4 columns: decimalLatitude, decimalLongitude, coordinateUncertaintyI… #>  #> ⠙ Checking 1 column: sex #> ✔ Checking 1 column: sex [311ms] #> obs_dwc |>   suggest_workflow() #>  #> ── Matching Darwin Core terms ────────────────────────────────────────────────── #> Matched 9 of 16 column names to DwC terms: #> ✔ Matched: basisOfRecord, coordinateUncertaintyInMeters, decimalLatitude, #>   decimalLongitude, eventDate, geodeticDatum, occurrenceID, scientificName, sex #> ✖ Unmatched: age_class, comments, landscape, molecular_sex, sample_id, site, #>   species_code #>  #> ── Minimum required Darwin Core terms ────────────────────────────────────────── #>  #>   Type                      Matched term(s)                                                                 Missing term(s)  #> ✔ Identifier (at least one) occurrenceID                                                                    -                 #> ✔ Record type               basisOfRecord                                                                   -                 #> ✔ Scientific name           scientificName                                                                  -                 #> ✔ Location                  decimalLatitude, decimalLongitude, geodeticDatum, coordinateUncertaintyInMeters -                 #> ✔ Date/Time                 eventDate                                                                       -                 #>  #>  #> 🥇 All minimum column requirements met! #>  #> ── Suggested workflow ────────────────────────────────────────────────────────── #>  #> 🥇 Your dataframe is Darwin Core compliant! #> Run checks, or use your dataframe to build a Darwin Core Archive with galaxias: #> df |> #>   check_dataset() #>  #> ── Additional functions #> Based on your matched terms, you can also add to your pipe: #> • `set_individual_traits()` #> ℹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms obs_dwc <- obs_dwc |>   select(any_of(occurrence_terms())) # select any matching terms  obs_dwc |>   gt::gt() |>   gt::opt_interactive(page_size_default = 5) # Save in ./data-processed write_csv(obs_dwc, file = \"./data-processed/occurrences.csv\")"},{"path":"https://galaxias.ala.org.au/articles/quick_start_guide.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Quick start guide","text":"existing R project containing data collected course research project. project uses fairly standard folder structure. Let’s see galaxias helps us prepare data Darwin Core Archive.","code":"├── README.md                        : Description of the repository ├── my-project-name.Rproj            : RStudio project file ├── data-raw                         : Folder to store original/source data ├── data                             : Folder to store cleaned data ├── scripts                          : Folder with analytic coding scripts └── plots                            : Folder containing plots/dataviz"},{"path":"https://galaxias.ala.org.au/articles/quick_start_guide.html","id":"use-standardised-data-in-an-archive","dir":"Articles","previous_headings":"","what":"Use standardised data in an archive","title":"Quick start guide","text":"Data wish share data folder. look something like . First, can standardise data conform Darwin Core Standard. ’ll using set_ functions automatically loaded galaxias. set_ functions work lot like dplyr::mutate(): can use modify create columns. suffix set_ function gives indication type data accepts (e.g. set_coordinates(), set_scientific_name). arguments valid Darwin Core terms use column names. see start standardising data, can use suggest_workflow() summarise data suggest steps take prepare my_data. Following advice suggest_workflow(), can use set_ functions standardise my_data. addition, set_ function checks make sure column contains valid data according Darwin Core Standard. Notice added several additional columns information data (country, locality, taxonRank, kingdom, family). encourage users specify additional information avoid ambiguity data shared. use standardised data Darwin Core Archive, can select columns use valid Darwin Core terms column names. Invalid columns won’t accepted try build Darwin Core Archive. data occurrence-based dataset (row contains information observation level, opposed site/survey level), ’ll select columns match names occurrence_terms(). Now can specify wish use my_data_dwc Darwin Core Archive use_data(), saves data data_publish folder correct file name occurrences.csv.","code":"## # A tibble: 2 × 6 ##   latitude longitude date       time  species                  location_id ##      <dbl>     <dbl> <chr>      <chr> <chr>                    <chr>       ## 1    -35.3      149. 14-01-2023 10:23 Callocephalon fimbriatum ARD001      ## 2    -35.3      149. 15-01-2023 11:25 Eolophus roseicapilla    ARD001 my_data |> suggest_workflow() #>  #> ── Matching Darwin Core terms ────────────────────────────────────────────────── #> Matched 0 of 6 column names to DwC terms: #> ✔ Matched: #> ✖ Unmatched: date, latitude, location_id, longitude, species, time #>  #> ── Minimum required Darwin Core terms ────────────────────────────────────────── #>  #>   Type                      Matched term(s)  Missing term(s)                                                                 #> ✖ Identifier (at least one) -                occurrenceID, catalogNumber, recordNumber                                        #> ✖ Record type               -                basisOfRecord                                                                    #> ✖ Scientific name           -                scientificName                                                                   #> ✖ Location                  -                decimalLatitude, decimalLongitude, geodeticDatum, coordinateUncertaintyInMeters  #> ✖ Date/Time                 -                eventDate #>  #> ── Suggested workflow ────────────────────────────────────────────────────────── #>  #> To make your data Darwin Core compliant, use the following workflow: #>  #> df |> #>   set_occurrences() |> #>   set_datetime() |> #>   set_coordinates() |> #>   set_scientific_name() #>  #> ── Additional functions #> ℹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms library(lubridate)  my_data_dwc <- df |>   # basic requirements of Darwin Core   set_occurrences(occurrenceID = composite_id(location_id,                                                sequential_id()),                   basisOfRecord = \"humanObservation\") |>    # place and time   set_coordinates(decimalLatitude = latitude,                    decimalLongitude = longitude) |>   set_locality(country = \"Australia\",                 locality = \"Canberra\") |>   set_datetime(eventDate = lubridate::dmy(date),                eventTime = lubridate::hm(time)) |>   # taxonomy   set_scientific_name(scientificName = species,                        taxonRank = \"species\") |>   set_taxonomy(kingdom = \"Animalia\",                 phylum = \"Aves\")   my_data_dwc |> print(n = 5) #> # A tibble: 2 × 13 #>   location_id basisOfRecord    occurrenceID decimalLatitude decimalLongitude #>   <chr>       <chr>            <chr>                  <dbl>            <dbl> #> 1 ARD001      humanObservation 01                     -35.3             149. #> 2 ARD001      humanObservation 02                     -35.3             149. #> # ℹ 8 more variables: country <chr>, locality <chr>, eventDate <date>, #> #   eventTime <Period>, scientificName <chr>, taxonRank <chr>, family <chr>, #> #   kingdom <chr> library(dplyr)  my_data_dwc <- my_data_dwc |>   select(any_of(occurrence_terms()))  my_data_dwc ## # A tibble: 2 × 12 ##   basisOfRecord    occurrenceID eventDate  eventTime  country   locality ##   <chr>            <chr>        <date>     <Period>   <chr>     <chr>    ## 1 humanObservation 01           2023-01-14 10H 23M 0S Australia Canberra ## 2 humanObservation 02           2023-01-15 11H 25M 0S Australia Canberra ## # ℹ 6 more variables: decimalLatitude <dbl>, decimalLongitude <dbl>, ## #   scientificName <chr>, kingdom <chr>, family <chr>, taxonRank <chr> use_data(my_data_dwc)"},{"path":"https://galaxias.ala.org.au/articles/quick_start_guide.html","id":"adding-metadata","dir":"Articles","previous_headings":"","what":"Adding metadata","title":"Quick start guide","text":"critical part Darwin Core archive metadata statement; tells users owns data, data collected , uses can put (.e. data licence). get example statement, call use_metadata_template(). default, creates R Markdown template named metadata.Rmd top working directory. ’s small example metadata.Rmd looks like. can edit template statement information wish convey data. metadata statement complete, can specify wish use Darwin Core Archive use_metadata(). converts markdown metadata statement Ecological Meta Language (EML), accepted format metadata Darwin Core Archives, saves eml.xml data-publish folder.","code":"use_metadata_template() use_metadata(\"metadata.Rmd\")"},{"path":"https://galaxias.ala.org.au/articles/quick_start_guide.html","id":"build-an-archive","dir":"Articles","previous_headings":"","what":"Build an archive","title":"Quick start guide","text":"end process, folder named data-publish contains least two files: One .csv files containing data (e.g. occurrences.csv, events.csv, multimedia.csv) eml.xml file containing metadata can now run build_archive() build Darwin Core Archive! Running build_archive() first checks whether ‘schema’ document (meta.xml) data-publish folder. machine-readable xml document describes content archive’s data files structure. schema document required file Darwin Core Archive. missing, build_archive() build one. can also build schema document using use_schema(). end process, Darwin Core Archive zip file (dwc-archive.zip). also data-publish folder containing standardised data files (e.g., occurrences.csv), metadata statement EML format (eml.xml), schema document (meta.xml). files can edited time update final Darwin Core Archive.","code":"build_archive()"},{"path":"https://galaxias.ala.org.au/articles/quick_start_guide.html","id":"check-archive","dir":"Articles","previous_headings":"","what":"Check archive","title":"Quick start guide","text":"several ways check whether contents Darwin Core Archive meet Darwin Core Standard. first run local tests files inside local folder directory used build Darwin Core Archive. check_directory() allows us check csv files xml files directory Darwin Core Standard criteria. second check whether complete Darwin Core Archive meets institution’s Darwin Core criteria via API. example, can test archive GBIF’s API tests.","code":"check_directory(\"data-publish\") # Add valid GBIF login details galaxias_config(GBIF = list(email = \"your-email\",                             username = \"your-username\",                             password = \"your-password\"))  # Check against GBIF API check_archive(\"dwc-archive.zip\")"},{"path":"https://galaxias.ala.org.au/articles/quick_start_guide.html","id":"publishshare-your-archive","dir":"Articles","previous_headings":"","what":"Publish/share your archive","title":"Quick start guide","text":"final step share completed Darwin Core Archive data infrastructure like Atlas Living Australia. share ALA, send file brief description support@ala.org.au.","code":""},{"path":"https://galaxias.ala.org.au/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Martin Westgate. Author, maintainer. Shandiya Balasubramaniam. Author. Dax Kellie. Author.","code":""},{"path":"https://galaxias.ala.org.au/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Westgate M, Balasubramaniam S, Kellie D (2025). galaxias: Describe, Package, Share Biodiversity Data. R package version 0.1.0, https://galaxias.ala.org.au.","code":"@Manual{,   title = {galaxias: Describe, Package, and Share Biodiversity Data},   author = {Martin Westgate and Shandiya Balasubramaniam and Dax Kellie},   year = {2025},   note = {R package version 0.1.0},   url = {https://galaxias.ala.org.au}, }"},{"path":[]},{"path":"https://galaxias.ala.org.au/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Describe, Package, and Share Biodiversity Data","text":"galaxias R package helps users describe, bundle share biodiversity information using ‘Darwin Core’ data standard. galaxias provides tools R build Darwin Core Archive, zip file containing standardised data metadata accepted global data infrastructures. package mirrors functionality devtools, usethis dplyr manage data, files folders. galaxias created Science & Decision Support Team Atlas Living Australia (ALA). package named genus freshwater fish found Southern Hemisphere, predominantly Australia New Zealand. logo shows Spotted Galaxias (Galaxias truttaceus) drawn Ian Brennan. comments, questions suggestions, please contact us.","code":""},{"path":"https://galaxias.ala.org.au/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Describe, Package, and Share Biodiversity Data","text":"package active development, yet available CRAN. can install latest development version GitHub : Load package:","code":"install.packages(\"remotes\") remotes::install_github(\"atlasoflivingaustralia/galaxias\") library(galaxias)"},{"path":"https://galaxias.ala.org.au/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Describe, Package, and Share Biodiversity Data","text":"galaxias contains tools : Standardise save data use_data(). Convert save metadata statements written Rmarkdown Quarto EML files use_metadata(). Build Darwin Core Archives sharing publication using build_archive(). Check files consistency Darwin Core Standard, either locally using check_directory(), via API using check_archive(). galaxias part group packages help users publish data using Darwin Core standard. packages loaded galaxias. packages : corella converting tibbles required column names delma converting markdown files xml","code":""},{"path":"https://galaxias.ala.org.au/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Describe, Package, and Share Biodiversity Data","text":"small example dataset species observations. can standardise data according Darwin Core Standard. standardised, can specify wish use standardised data Darwin Core Archive.use_data() saves df_dwc valid csv file name location. Create template metadata statement data. editing, can specify wish use metadata Darwin Core Archive. use_metadata() converts metadata EML format saves valid xml file name location. Build Darwin Core Archive save parent directory working directory. Validate whether constructed archive passes Darwin Core Standard criteria. See Quick Start Guide -depth explanation building Darwin Core Archives.","code":"library(tibble)  df <- tibble(   scientificName = c(\"Callocephalon fimbriatum\", \"Eolophus roseicapilla\"),   latitude = c(-35.310, -35.273),    longitude = c(149.125, 149.133),   eventDate = lubridate::dmy(c(\"14-01-2023\", \"15-01-2023\")),   status = c(\"present\", \"present\") )  df #> # A tibble: 2 × 5 #>   scientificName           latitude longitude eventDate  status  #>   <chr>                       <dbl>     <dbl> <date>     <chr>   #> 1 Callocephalon fimbriatum    -35.3      149. 2023-01-14 present #> 2 Eolophus roseicapilla       -35.3      149. 2023-01-15 present df_dwc <- df |>    set_occurrences(occurrenceID = random_id(),                    basisOfRecord = \"humanObservation\",                    occurrenceStatus = status) |>    set_coordinates(decimalLatitude = latitude,                    decimalLongitude = longitude)  df_dwc #> # A tibble: 2 × 7 #>   scientificName          eventDate  basisOfRecord occurrenceID occurrenceStatus #>   <chr>                   <date>     <chr>         <chr>        <chr>            #> 1 Callocephalon fimbriat… 2023-01-14 humanObserva… 075b4280-31… present          #> 2 Eolophus roseicapilla   2023-01-15 humanObserva… 075b4294-31… present          #> # ℹ 2 more variables: decimalLatitude <dbl>, decimalLongitude <dbl> use_data(df_dwc) use_metadata_template(\"metadata.Rmd\") use_metadata(\"metadata.Rmd\") build_archive() check_archive()"},{"path":"https://galaxias.ala.org.au/index.html","id":"citing-galaxias","dir":"","previous_headings":"","what":"Citing galaxias","title":"Describe, Package, and Share Biodiversity Data","text":"generate citation package version using, can run: current recommended citation : Westgate MJ, Balasubramaniam S & Kellie D (2024) galaxias: Standardise, Document Share Biodiversity Data. R Package version 0.1.0.","code":"citation(package = \"galaxias\")"},{"path":"https://galaxias.ala.org.au/index.html","id":"contributors","dir":"","previous_headings":"","what":"Contributors","title":"Describe, Package, and Share Biodiversity Data","text":"Developers contributed galaxias follows (alphabetical order surname): Amanda Buyan (@acbuyan), Fonti Kar (@fontikar), Peggy Newman (@peggynewman) & Andrew Schwenke (@andrew-1234)","code":""},{"path":"https://galaxias.ala.org.au/reference/build_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a Darwin Core Archive from a folder — build_archive","title":"Build a Darwin Core Archive from a folder — build_archive","text":"Darwin Core archive zip file containing specified combination data metadata. build_archive() constructs zip file. assumes necessary files pre-constructed, can found inside single folder additional redundant information. Structurally, build_archive() similar devtools::build(), sense takes repository wraps publication.","code":""},{"path":"https://galaxias.ala.org.au/reference/build_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a Darwin Core Archive from a folder — build_archive","text":"","code":"build_archive(destination = \"dwc-archive.zip\")"},{"path":"https://galaxias.ala.org.au/reference/build_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a Darwin Core Archive from a folder — build_archive","text":"destination (string) file name save resulting zip file. Defaults ./dwc-archive.zip.","code":""},{"path":"https://galaxias.ala.org.au/reference/build_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a Darwin Core Archive from a folder — build_archive","text":"Invisibly returns location built zip file; typically called side-effect building 'Darwin Core Archive' (.e. zip file).","code":""},{"path":"https://galaxias.ala.org.au/reference/build_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build a Darwin Core Archive from a folder — build_archive","text":"function looks three types objects specified directory: Data One csv files named occurrences.csv, events.csv /multimedia.csv. csv files contain data standardised using Darwin Core Standard (see corella::corella-package() details). data.frame/tibble can added correct folder using use_data(). Metadata metadata statement EML format file name eml.xml. Completed metadata statements written markdown .Rmd qmd files can converted saved correct folder using use_metadata(). Create new template use_metadata_template(). Schema 'schema' document xml format file name meta.xml. file can constructed using use_schema(). build_archive() build Darwin Core Archive files present source directory. resulting Archive saved zip folder parent directory default.","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/reference/check_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether a Darwin Core Archive meets Darwin Core Standard via API — check_archive","title":"Check whether a Darwin Core Archive meets Darwin Core Standard via API — check_archive","text":"Check whether specified Darwin Core Archive ready sharing publication, according Darwin Core Standard. check_archive() tests specified archive using online validation service sending archive via API returning results. Currently supports validation using GBIF.","code":""},{"path":"https://galaxias.ala.org.au/reference/check_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether a Darwin Core Archive meets Darwin Core Standard via API — check_archive","text":"","code":"check_archive(source = \"dwc-archive.zip\", provider = \"GBIF\")  get_report(key)"},{"path":"https://galaxias.ala.org.au/reference/check_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether a Darwin Core Archive meets Darwin Core Standard via API — check_archive","text":"source (string) file name (ending .zip) specified Darwin Core Archive. Defaults dwc-archive.zip within top folder current working directory. provider (string) institution queried validation services. Currently \"GBIF\" supported. key unique identifier key GBIF","code":""},{"path":"https://galaxias.ala.org.au/reference/check_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether a Darwin Core Archive meets Darwin Core Standard via API — check_archive","text":"Invisibly returns tibble workspace containing validation results; primarily called side-effect generating report console.","code":""},{"path":"https://galaxias.ala.org.au/reference/check_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check whether a Darwin Core Archive meets Darwin Core Standard via API — check_archive","text":"Results returned check_archive() directly institution API, galaxias.","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/reference/check_archive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether a Darwin Core Archive meets Darwin Core Standard via API — check_archive","text":"","code":"if (FALSE) { # \\dontrun{ # add GBIF login details galaxias_config(gbif = list(username = \"your-gbif-username\",                             email = \"your-gbif-email\",                             password = \"your-gbif-password\"))  # Check archive against Darwin Core Standard criteria check_archive(\"dwc-archive.zip\") } # }"},{"path":"https://galaxias.ala.org.au/reference/check_directory.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether contents of folder directory meet Darwin Core Standard — check_directory","title":"Check whether contents of folder directory meet Darwin Core Standard — check_directory","text":"Supply folder containing files Darwin Core Archive check whether files meet Darwin Core Standard. check_archive() runs corella::check_dataset() occurrences.csv events.csv files, delma::check_metadata() eml.xml meta.xml files. functions run tests determine whether data metadata pass Darwin Core Standard criteria.","code":""},{"path":"https://galaxias.ala.org.au/reference/check_directory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether contents of folder directory meet Darwin Core Standard — check_directory","text":"","code":"check_directory(source = \"data-publish\")"},{"path":"https://galaxias.ala.org.au/reference/check_directory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether contents of folder directory meet Darwin Core Standard — check_directory","text":"source (string) directory containing files published, optionally .zip file built (.e. build_archive()). Defaults data-publish folder within current working directory.","code":""},{"path":"https://galaxias.ala.org.au/reference/check_directory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether contents of folder directory meet Darwin Core Standard — check_directory","text":"Invisibly returns tibble workspace containing check results; primarily called side-effect generating report console.","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/reference/check_directory.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether contents of folder directory meet Darwin Core Standard — check_directory","text":"","code":"# \\donttest{ # Run checks csv or xml files in specified directory # Defaults to folder data-publish/  check_directory() #> Error in check_directory(): File or directory data-publish not found.  # }"},{"path":"https://galaxias.ala.org.au/reference/galaxias-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Build repositories to share biodiversity data — galaxias-package","title":"Build repositories to share biodiversity data — galaxias-package","text":"galaxias helps users describe, package share biodiversity information using 'Darwin Core' data standard, format used accepted Global Biodiversity Information Facility (GBIF) ' partner nodes. galaxias functionally similar devtools, focus building Darwin Core Archives rather R packages. package named genus freshwater fish.","code":""},{"path":"https://galaxias.ala.org.au/reference/galaxias-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Build repositories to share biodiversity data — galaxias-package","text":"questions, comments suggestions, please email support@ala.org.au. Prepare information Darwin Core use_metadata_template() Add blank metadata statement template working directory suggest_workflow() Advice standardise data using Darwin Core Standard Add information folder use_data() Save standardised data use Darwin Core Archive use_metadata() Convert metadata file markdown EML (eml.xml) save use Darwin Core Archive use_schema() Build schema file (meta.xml) given directory save use Darwin Core Archive Build archive build_archive() Convert directory Darwin Core Archive Verify archive meets Darwin Core Standard check_directory() Check files local Darwin Core directory check_archive() Check whether archive passes Darwin Core criteria via GBIF API galaxias_config() Store credentials API call print_report() Methods displaying API responses","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/reference/galaxias-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Build repositories to share biodiversity data — galaxias-package","text":"Maintainer: Martin Westgate martin.westgate@csiro.au Authors: Shandiya Balasubramaniam shandiya.balasubramaniam@csiro.au Dax Kellie dax.kellie@csiro.au","code":""},{"path":"https://galaxias.ala.org.au/reference/galaxias_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Provide configuration information to galaxias — galaxias_config","title":"Provide configuration information to galaxias — galaxias_config","text":"validate (future, publish) dataset, need provide credentials relevant web service. function allows store information access galaxias API functions. function also enables change directory working documents stored, defaults data-publish.","code":""},{"path":"https://galaxias.ala.org.au/reference/galaxias_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provide configuration information to galaxias — galaxias_config","text":"","code":"galaxias_config(directory = NULL, gbif = NULL)  # S3 method for class 'galaxias_config' print(x, ...)"},{"path":"https://galaxias.ala.org.au/reference/galaxias_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provide configuration information to galaxias — galaxias_config","text":"directory string giving name directory used storing working files. Defaults data-publish. gbif list containing entries username, email password. x object class galaxias_config, created galaxias_config(). ... Additional arguments, currently ignored.","code":""},{"path":"https://galaxias.ala.org.au/reference/galaxias_config.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Provide configuration information to galaxias — galaxias_config","text":"Note unlike galah, set 'default' provider galaxias; organisation always argument function question. Also unlike galah, galaxias_config() enables store configuration details multiple organisations .","code":""},{"path":"https://galaxias.ala.org.au/reference/print_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Print objects returned by APIs — print_report","title":"Print objects returned by APIs — print_report","text":"Currently check_archive() get_report(), latter called former.","code":""},{"path":"https://galaxias.ala.org.au/reference/print_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print objects returned by APIs — print_report","text":"","code":"# S3 method for class 'gbif_validator_post' print(x, ...)  # S3 method for class 'gbif_validator_response' print(x, n = 5, ...)"},{"path":"https://galaxias.ala.org.au/reference/print_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print objects returned by APIs — print_report","text":"x object print. ... Additional arguments, currently ignored. n Number entries print","code":""},{"path":"https://galaxias.ala.org.au/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. corella suggest_workflow delma use_metadata_template","code":""},{"path":"https://galaxias.ala.org.au/reference/use_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Use standardised data in a Darwin Core Archive — use_data","title":"Use standardised data in a Darwin Core Archive — use_data","text":"data conform Darwin Core Standard, use_data() makes easy save data correct place building Darwin Core Archive build_archive(). use_data() --one function accepted data types \"occurrence\", \"event\" \"multimedia\". use_data() attempts detect save correct data type based provided tibble/data.frame. Alternatively, users can call underlying functions use_data_occurrences(), use_data_events() use_data_multimedia() specify data type manually.","code":""},{"path":"https://galaxias.ala.org.au/reference/use_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use standardised data in a Darwin Core Archive — use_data","text":"","code":"use_data(..., overwrite = FALSE)  use_data_occurrences(df, overwrite = FALSE)  use_data_events(df, overwrite = FALSE)"},{"path":"https://galaxias.ala.org.au/reference/use_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use standardised data in a Darwin Core Archive — use_data","text":"... Unquoted name tibble/data.frame save. overwrite default, use_data_events() overwrite existing files. really want , set TRUE. df tibble/data.frame save.","code":""},{"path":"https://galaxias.ala.org.au/reference/use_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use standardised data in a Darwin Core Archive — use_data","text":"Invisibly returns location saved csv file.","code":""},{"path":"https://galaxias.ala.org.au/reference/use_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use standardised data in a Darwin Core Archive — use_data","text":"default, function saves data data-publish folder. change default, see galaxias_config(). Data type determined detecting type-specific column names supplied data. Event: (eventID, parentEventID, eventType) Multimedia: yet supported","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/reference/use_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Use a metadata statement in a Darwin Core Archive — use_metadata","title":"Use a metadata statement in a Darwin Core Archive — use_metadata","text":"metadata statement lists owner dataset, collected, can used (.e. ' licence). function reads converts metadata saved markdown (.md), Rmarkdown (.Rmd) Quarto (.qmd) xml, saves destination folder. function convenience wrapper function delma::read_md() delma::write_eml().","code":""},{"path":"https://galaxias.ala.org.au/reference/use_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use a metadata statement in a Darwin Core Archive — use_metadata","text":"","code":"use_metadata(   source = \"metadata.Rmd\",   destination = \"eml.xml\",   overwrite = FALSE )"},{"path":"https://galaxias.ala.org.au/reference/use_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use a metadata statement in a Darwin Core Archive — use_metadata","text":"source metadata file markdown (.md), Rmarkdown (.Rmd) Quarto markdown (.qmd). Defaults metadata.md, created use_metadata_template() destination file name save resulting .xml file. Defaults eml.xml. Note file saved data-publish directory, unless changed using directory argument galaxias_config(). overwrite default, use_metadata() overwrite existing files. really want , set TRUE.","code":""},{"path":"https://galaxias.ala.org.au/reference/use_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use a metadata statement in a Darwin Core Archive — use_metadata","text":"return object workspace; called side effect building file data-publish directory.","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/reference/use_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a schema for a Darwin Core Archive — use_schema","title":"Create a schema for a Darwin Core Archive — use_schema","text":"schema xml document maps files field names DwCA. map makes easier reconstruct one related datasets information matched correctly. works detecting column names csv files specified directory; Darwin Core terms function produce reliable results.","code":""},{"path":"https://galaxias.ala.org.au/reference/use_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a schema for a Darwin Core Archive — use_schema","text":"","code":"use_schema(source = \"data-publish\", destination = \"meta.xml\")"},{"path":"https://galaxias.ala.org.au/reference/use_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a schema for a Darwin Core Archive — use_schema","text":"source folder containing one data csv files occurrences.csv, events.csv multimedia.csv. Defaults data-publish/. destination file name resulting schema document. Defaults meta.xml consistency Darwin Core standard. Note file placed within working directory specified galaxias_config().","code":""},{"path":"https://galaxias.ala.org.au/reference/use_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a schema for a Darwin Core Archive — use_schema","text":"return object workspace; called side effect building schema file specified directory.","code":""},{"path":"https://galaxias.ala.org.au/news/index.html","id":"galaxias-010","dir":"Changelog","previous_headings":"","what":"galaxias 0.1.0","title":"galaxias 0.1.0","text":"First release version. hope like !","code":""}]
