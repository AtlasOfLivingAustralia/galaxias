[{"path":"https://galaxias.ala.org.au/R/articles/events-example.html","id":"the-dataset","dir":"Articles","previous_headings":"","what":"The dataset","title":"Standardise an Events dataset","text":"example, â€™ll use sample dataset containing observations frogs. Data collected using 5-minute audio surveys, row records whether frog species detected within 5-minute audio recording, recorded present (1) absent (0). First, letâ€™s view list eight frog species recorded dataset. abbreviation column contains abbreviated column name used observational dataset. Now letâ€™s view observational dataset. data contains columns describe site location (e.g.Â site_code, water_type, veg_canopy) columns containing data whether frog species present absent sample (e.g.Â cpar, csig, limdum). :::{.panel-tabset}","code":"library(readxl) library(dplyr) library(tidyr)  species <- read_xlsx(\"Frogwatch_dataset.xlsx\",                       sheet = \"species list\") |>    janitor::clean_names()  species ## # A tibble: 8 Ã— 3 ##   scientific_name            common_name            abbreviation ##   <chr>                      <chr>                  <chr>        ## 1 Crinia parinsignifera      Plains Froglet         cpar         ## 2 Crinia signifera           Common Eastern Froglet csig         ## 3 Limnodynastes dumerilii    Pobblebonk             limdum       ## 4 Limnodynastes peronii      Striped Marsh Frog     limper       ## 5 Limnodynastes tasmaniensis Spotted Grass Frog     limtas       ## 6 Litoria peronii            Emerald Spotted Frog   lper         ## 7 Litoria verreauxii         Alpine Tree Frog       lver         ## 8 Uperoleia laevigata        Smooth Toadlet         ulae obs <- read_xlsx(\"Frogwatch_dataset.xlsx\",                   sheet = \"observations\") |>   janitor::clean_names()"},{"path":"https://galaxias.ala.org.au/R/articles/events-example.html","id":"glimpse","dir":"Articles","previous_headings":"","what":"Glimpse","title":"Standardise an Events dataset","text":"","code":"obs |> tibble::glimpse() ## Rows: 3,633 ## Columns: 18 ## $ site_code  <chr> \"AMA100\", \"AMA100\", \"AMA100\", \"AMA100\", \"AMA100\", \"AMA100\",â€¦ ## $ year       <dbl> 2004, 2007, 2007, 2005, 2008, 2008, 2013, 2008, 2013, 2014,â€¦ ## $ depth      <chr> \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deâ€¦ ## $ water_type <chr> \"moving\", \"moving\", \"moving\", \"moving\", \"moving\", \"moving\",â€¦ ## $ log_size   <dbl> 2.9145355, 2.9145355, 2.9145355, 2.9145355, 2.9145355, 2.91â€¦ ## $ veg_aqu    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,â€¦ ## $ veg_canopy <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,â€¦ ## $ veg_bank   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,â€¦ ## $ pc_urban   <dbl> 0.2260, 0.2067, 0.2067, 0.2813, 0.2067, 0.2067, 0.2200, 0.2â€¦ ## $ pc_canopy  <dbl> 0.0427, 0.0987, 0.0987, 0.0567, 0.0607, 0.0607, 0.0860, 0.0â€¦ ## $ cpar       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ ## $ csig       <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ ## $ limdum     <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ ## $ limper     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,â€¦ ## $ limtas     <dbl> 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,â€¦ ## $ lper       <dbl> 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ ## $ lver       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ ## $ ulae       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦"},{"path":"https://galaxias.ala.org.au/R/articles/events-example.html","id":"sample","dir":"Articles","previous_headings":"","what":"Sample","title":"Standardise an Events dataset","text":"::: observational dataset wide format. row represents one sample, containing multiple observations. Darwin Core Archive, require data long format, row contains one observation. Letâ€™s make adjustment added hierarchical structure data collection (ie Site -> Sample -> Occurrence) adds richness ecological data. Events data can also allow recording presences absences data, enables nuanced probabilistic analyses like species distribution models occupancy models.","code":"obs |>    print(n = 8) |>   rmarkdown::paged_table() ## # A tibble: 3,633 Ã— 18 ##   site_code  year depth water_type log_size veg_aqu veg_canopy veg_bank pc_urban ##   <chr>     <dbl> <chr> <chr>         <dbl>   <dbl>      <dbl>    <dbl>    <dbl> ## 1 AMA100     2004 deep  moving         2.91       1          0        1    0.226 ## 2 AMA100     2007 deep  moving         2.91       1          0        1    0.207 ## 3 AMA100     2007 deep  moving         2.91       1          0        1    0.207 ## 4 AMA100     2005 deep  moving         2.91       1          0        1    0.281 ## 5 AMA100     2008 deep  moving         2.91       1          0        1    0.207 ## 6 AMA100     2008 deep  moving         2.91       1          0        1    0.207 ## 7 AMA100     2013 deep  moving         2.91       1          0        1    0.22  ## 8 AMA100     2008 deep  moving         2.91       1          0        1    0.207 ## # â„¹ 3,625 more rows ## # â„¹ 9 more variables: pc_canopy <dbl>, cpar <dbl>, csig <dbl>, limdum <dbl>, ## #   limper <dbl>, limtas <dbl>, lper <dbl>, lver <dbl>, ulae <dbl> obs |>   select(site_code, any_of(species$abbreviation)) |>   pivot_longer(cols = species$abbreviation,                names_to = \"abbreviation\") |>   left_join(species, by = \"abbreviation\", keep = FALSE) |>   select(-abbreviation) |>   relocate(value, .after = last_col()) ## # A tibble: 29,064 Ã— 4 ##    site_code scientific_name            common_name            value ##    <chr>     <chr>                      <chr>                  <dbl> ##  1 AMA100    Crinia parinsignifera      Plains Froglet             1 ##  2 AMA100    Crinia signifera           Common Eastern Froglet     0 ##  3 AMA100    Limnodynastes dumerilii    Pobblebonk                 0 ##  4 AMA100    Limnodynastes peronii      Striped Marsh Frog         0 ##  5 AMA100    Limnodynastes tasmaniensis Spotted Grass Frog         1 ##  6 AMA100    Litoria peronii            Emerald Spotted Frog       1 ##  7 AMA100    Litoria verreauxii         Alpine Tree Frog           0 ##  8 AMA100    Uperoleia laevigata        Smooth Toadlet             0 ##  9 AMA100    Crinia parinsignifera      Plains Froglet             1 ## 10 AMA100    Crinia signifera           Common Eastern Froglet     0 ## # â„¹ 29,054 more rows sites <- read_xlsx(\"Frogwatch_dataset.xlsx\",                     sheet = \"sites\") |>   janitor::clean_names()"},{"path":"https://galaxias.ala.org.au/R/articles/occurrences-example.html","id":"the-dataset","dir":"Articles","previous_headings":"","what":"The dataset","title":"Standardise an Occurrences dataset","text":"Letâ€™s use small example dataset bird observations taken 4 different site locations. dataset many different types data like landscape type age class. Importantly standardising Darwin Core, dataset contains scientific name (species), coordinate location (lat & lon) date observation (date).","code":"library(galaxias) library(dplyr) library(readxl)  obs <- read_xlsx(\"dummy-dataset-sb.xlsx\",                  sheet = 1) |>   janitor::clean_names()  obs |>    gt::gt() |>   gt::opt_interactive(page_size_default = 5)"},{"path":"https://galaxias.ala.org.au/R/articles/occurrences-example.html","id":"standardise-to-darwin-core","dir":"Articles","previous_headings":"","what":"Standardise to Darwin Core","title":"Standardise an Occurrences dataset","text":"determine need standardise dataset, letâ€™s use suggest_workflow(). output tells us one matching Darwin Core term data already (sex), missing minimum required Darwin Core terms. â€œSuggest workflowâ€, output suggests series piped set_ functions can use rename, modify add columns missing obs required Darwin Core. set_ functions specialised wrappers around dplyr::mutate(), additional functionality support using Darwin Core Standard. simplicity, letâ€™s easy part first renaming columns already dataset use accepted standard Darwin Core terms. set_ functions automatically check make sure column correctly formatted. â€™ll save modified dataframe obs_dwc. Running suggest_workflow() reflect progress show us â€™s left . Now output tells us still need add several columns dataset meet minimum Darwin Core requirements. â€™s rundown columns need add: occurrenceID: Unique identifiers record. ensures can identify specific record future updates corrections. can use composite_id(), sequential_id() random_id() add unique IDs row. basisOfRecord: type record (e.g.Â human observation, specimen, machine observation). See list acceptable values corella::basisOfRecord_values(). geodeticDatum: Coordinate Reference System (CRS) projection data (example, CRS Google Maps â€œWGS84â€). coordinateUncertaintyInMeters: area uncertainty around observation. may know value based method data collection Now letâ€™s add columns using set_occurrences() set_coordinates(). can also add suggested function set_individual_traits() automatically identify matched column name sex check columnâ€™s format. Running suggest_workflow() confirm dataset ready used Darwin Core Archive! submit dataset, letâ€™s select columns valid occurrence term names save dataframe file occurrences.csv. Importantly, save csv folder called data-processed, galaxias looks automatically building Darwin Core Archive. final step save â€˜publishingâ€™ directory: done! See Quick start guide vignette build Darwin Core Archive.","code":"obs |>   suggest_workflow() #>  #> â”€â”€ Matching Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Matched 1 of 12 column names to DwC terms: #> âœ” Matched: sex #> âœ– Unmatched: age_class, comments, date, landscape, lat, lon, molecular_sex, #>   sample_id, site, species, species_code #>  #> â”€â”€ Minimum required Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #>   Type                      Matched term(s)  Missing term(s)                                                                 #> âœ– Identifier (at least one) -                occurrenceID, catalogNumber, recordNumber                                        #> âœ– Record type               -                basisOfRecord                                                                    #> âœ– Scientific name           -                scientificName                                                                   #> âœ– Location                  -                decimalLatitude, decimalLongitude, geodeticDatum, coordinateUncertaintyInMeters  #> âœ– Date/Time                 -                eventDate #>  #> â”€â”€ Suggested workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #> To make your data Darwin Core compliant, use the following workflow: #>  #> df |> #>   set_occurrences() |> #>   set_datetime() |> #>   set_coordinates() |> #>   set_scientific_name() #>  #> â”€â”€ Additional functions #> Based on your matched terms, you can also add to your pipe: #> â€¢ `set_individual_traits()` #> â„¹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms obs_dwc <- obs |>   set_scientific_name(scientificName = species) |>   set_coordinates(decimalLatitude = lat,                   decimalLongitude = lon) |>   set_datetime(eventDate = lubridate::ymd(date)) # specify year-month-day format #> â ™ Checking 1 column: scientificName #> âœ” Checking 1 column: scientificName [319ms] #>  #> â ™ Checking 2 columns: decimalLatitude and decimalLongitude #> â ¹ Checking 2 columns: decimalLatitude and decimalLongitude #> âœ” Checking 2 columns: decimalLatitude and decimalLongitude [631ms] #>  #> â ™ Checking 1 column: eventDate #> âœ” Checking 1 column: eventDate [310ms] #> obs_dwc |>   suggest_workflow() #>  #> â”€â”€ Matching Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Matched 5 of 12 column names to DwC terms: #> âœ” Matched: decimalLatitude, decimalLongitude, eventDate, scientificName, sex #> âœ– Unmatched: age_class, comments, landscape, molecular_sex, sample_id, site, #>   species_code #>  #> â”€â”€ Minimum required Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #>   Type                      Matched term(s)                  Missing term(s)                             #> âœ” Scientific name           scientificName                   -                                            #> âœ” Date/Time                 eventDate                        -                                            #> âœ– Identifier (at least one) -                                occurrenceID, catalogNumber, recordNumber    #> âœ– Record type               -                                basisOfRecord                                #> âœ– Location                  decimalLatitude decimalLongitude geodeticDatum coordinateUncertaintyInMeters #>  #> â”€â”€ Suggested workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #> To make your data Darwin Core compliant, use the following workflow: #>  #> df |> #>   set_occurrences() |> #>   set_coordinates() #>  #> â”€â”€ Additional functions #> Based on your matched terms, you can also add to your pipe: #> â€¢ `set_individual_traits()` #> â„¹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms obs_dwc <- obs_dwc |>   set_occurrences(     occurrenceID = composite_id(sequential_id(), site, landscape),     basisOfRecord = \"humanObservation\"     ) |>   set_coordinates(     geodeticDatum = \"WGS84\",     coordinateUncertaintyInMeters = 30     # coordinateUncertaintyInMeters = with_uncertainty(method = \"phone\")     ) |>   set_individual_traits() #> â ™ Checking 2 columns: occurrenceID and basisOfRecord #> âœ” Checking 2 columns: occurrenceID and basisOfRecord [618ms] #>  #> â ™ Checking 4 columns: decimalLatitude, decimalLongitude, coordinateUncertaintyIâ€¦ #> â ¹ Checking 4 columns: decimalLatitude, decimalLongitude, coordinateUncertaintyIâ€¦ #> âœ” Checking 4 columns: decimalLatitude, decimalLongitude, coordinateUncertaintyIâ€¦ #>  #> â ™ Checking 1 column: sex #> âœ” Checking 1 column: sex [310ms] #> obs_dwc |>   suggest_workflow() #>  #> â”€â”€ Matching Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Matched 9 of 16 column names to DwC terms: #> âœ” Matched: basisOfRecord, coordinateUncertaintyInMeters, decimalLatitude, #>   decimalLongitude, eventDate, geodeticDatum, occurrenceID, scientificName, sex #> âœ– Unmatched: age_class, comments, landscape, molecular_sex, sample_id, site, #>   species_code #>  #> â”€â”€ Minimum required Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #>   Type                      Matched term(s)                                                                 Missing term(s)  #> âœ” Identifier (at least one) occurrenceID                                                                    -                 #> âœ” Record type               basisOfRecord                                                                   -                 #> âœ” Scientific name           scientificName                                                                  -                 #> âœ” Location                  decimalLatitude, decimalLongitude, geodeticDatum, coordinateUncertaintyInMeters -                 #> âœ” Date/Time                 eventDate                                                                       -                 #>  #>  #> ðŸ¥‡ All minimum column requirements met! #>  #> â”€â”€ Suggested workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #> ðŸ¥‡ Your dataframe is Darwin Core compliant! #> Run checks, or use your dataframe to build a Darwin Core Archive with galaxias: #> df |> #>   check_dataset() #>  #> â”€â”€ Additional functions #> Based on your matched terms, you can also add to your pipe: #> â€¢ `set_individual_traits()` #> â„¹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms obs_dwc <- obs_dwc |>   select(any_of(occurrence_terms())) # select any matching terms  obs_dwc |>   gt::gt() |>   gt::opt_interactive(page_size_default = 5) # Save in ./data-processed use_data_occurrences(obs_dwc)"},{"path":"https://galaxias.ala.org.au/R/articles/quick_start_guide.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Quick start guide","text":"existing R project containing data collected course research project. project uses fairly standard folder structure. Letâ€™s see galaxias helps us prepare data Darwin Core Archive.","code":"â”œâ”€â”€ README.md                        : Description of the repository â”œâ”€â”€ my-project-name.Rproj            : RStudio project file â”œâ”€â”€ data-raw                         : Folder to store original/source data â”œâ”€â”€ data                             : Folder to store cleaned data â”œâ”€â”€ scripts                          : Folder with analytic coding scripts â””â”€â”€ plots                            : Folder containing plots/dataviz"},{"path":"https://galaxias.ala.org.au/R/articles/quick_start_guide.html","id":"use-standardised-data-in-an-archive","dir":"Articles","previous_headings":"","what":"Use standardised data in an archive","title":"Quick start guide","text":"Data wish share data folder. look something like . First, can standardise data conform Darwin Core Standard. â€™ll using set_ functions automatically loaded galaxias. set_ functions work lot like dplyr::mutate(): can use modify create columns. suffix set_ function gives indication type data accepts (e.g.Â set_coordinates(), set_scientific_name). arguments valid Darwin Core terms use column names. see start standardising data, can use suggest_workflow() summarise data suggest steps take prepare my_data. Following advice suggest_workflow(), can use set_ functions standardise my_data. addition, set_ function checks make sure column contains valid data according Darwin Core Standard. Notice added several additional columns information data (country, locality, taxonRank, kingdom, family). encourage users specify additional information avoid ambiguity data shared. use standardised data Darwin Core Archive, can select columns use valid Darwin Core terms column names. Invalid columns wonâ€™t accepted try build Darwin Core Archive. data occurrence-based dataset (row contains information observation level, opposed site/survey level), â€™ll select columns match names occurrence_terms(). Now can specify wish use my_data_dwc Darwin Core Archive use_data(), saves data data_publish folder correct file name occurrences.csv.","code":"## # A tibble: 2 Ã— 6 ##   latitude longitude date       time  species                  location_id ##      <dbl>     <dbl> <chr>      <chr> <chr>                    <chr>       ## 1    -35.3      149. 14-01-2023 10:23 Callocephalon fimbriatum ARD001      ## 2    -35.3      149. 15-01-2023 11:25 Eolophus roseicapilla    ARD001 my_data |> suggest_workflow() #>  #> â”€â”€ Matching Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Matched 0 of 6 column names to DwC terms: #> âœ” Matched: #> âœ– Unmatched: date, latitude, location_id, longitude, species, time #>  #> â”€â”€ Minimum required Darwin Core terms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #>   Type                      Matched term(s)  Missing term(s)                                                                 #> âœ– Identifier (at least one) -                occurrenceID, catalogNumber, recordNumber                                        #> âœ– Record type               -                basisOfRecord                                                                    #> âœ– Scientific name           -                scientificName                                                                   #> âœ– Location                  -                decimalLatitude, decimalLongitude, geodeticDatum, coordinateUncertaintyInMeters  #> âœ– Date/Time                 -                eventDate #>  #> â”€â”€ Suggested workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #>  #> To make your data Darwin Core compliant, use the following workflow: #>  #> df |> #>   set_occurrences() |> #>   set_datetime() |> #>   set_coordinates() |> #>   set_scientific_name() #>  #> â”€â”€ Additional functions #> â„¹ See all `set_` functions at #>   http://corella.ala.org.au/reference/index.html#add-rename-or-edit-columns-to-match-darwin-core-terms library(lubridate)  my_data_dwc <- df |>   # basic requirements of Darwin Core   set_occurrences(occurrenceID = composite_id(location_id,                                                sequential_id()),                   basisOfRecord = \"humanObservation\") |>    # place and time   set_coordinates(decimalLatitude = latitude,                    decimalLongitude = longitude) |>   set_locality(country = \"Australia\",                 locality = \"Canberra\") |>   set_datetime(eventDate = lubridate::dmy(date),                eventTime = lubridate::hm(time)) |>   # taxonomy   set_scientific_name(scientificName = species,                        taxonRank = \"species\") |>   set_taxonomy(kingdom = \"Animalia\",                 phylum = \"Aves\")   my_data_dwc |> print(n = 5) #> # A tibble: 2 Ã— 13 #>   location_id basisOfRecord    occurrenceID decimalLatitude decimalLongitude #>   <chr>       <chr>            <chr>                  <dbl>            <dbl> #> 1 ARD001      humanObservation 01                     -35.3             149. #> 2 ARD001      humanObservation 02                     -35.3             149. #> # â„¹ 8 more variables: country <chr>, locality <chr>, eventDate <date>, #> #   eventTime <Period>, scientificName <chr>, taxonRank <chr>, family <chr>, #> #   kingdom <chr> library(dplyr)  my_data_dwc <- my_data_dwc |>   select(any_of(occurrence_terms()))  my_data_dwc ## # A tibble: 2 Ã— 12 ##   basisOfRecord    occurrenceID eventDate  eventTime  country   locality ##   <chr>            <chr>        <date>     <Period>   <chr>     <chr>    ## 1 humanObservation 01           2023-01-14 10H 23M 0S Australia Canberra ## 2 humanObservation 02           2023-01-15 11H 25M 0S Australia Canberra ## # â„¹ 6 more variables: decimalLatitude <dbl>, decimalLongitude <dbl>, ## #   scientificName <chr>, kingdom <chr>, family <chr>, taxonRank <chr> use_data(my_data_dwc)"},{"path":"https://galaxias.ala.org.au/R/articles/quick_start_guide.html","id":"adding-metadata","dir":"Articles","previous_headings":"","what":"Adding metadata","title":"Quick start guide","text":"critical part Darwin Core archive metadata statement; tells users owns data, data collected , uses can put (.e.Â data licence). get example statement, call use_metadata_template(). default, creates R Markdown template named metadata.Rmd top working directory. â€™s small example metadata.Rmd looks like. can edit template statement information wish convey data. metadata statement complete, can specify wish use Darwin Core Archive use_metadata(). converts markdown metadata statement Ecological Meta Language (EML), accepted format metadata Darwin Core Archives, saves eml.xml data-publish folder.","code":"use_metadata_template() use_metadata(\"metadata.Rmd\")"},{"path":"https://galaxias.ala.org.au/R/articles/quick_start_guide.html","id":"build-an-archive","dir":"Articles","previous_headings":"","what":"Build an archive","title":"Quick start guide","text":"end process, folder named data-publish contains least two files: One .csv files containing data (e.g.Â occurrences.csv, events.csv, multimedia.csv) eml.xml file containing metadata can now run build_archive() build Darwin Core Archive! Running build_archive() first checks whether â€˜schemaâ€™ document (meta.xml) data-publish folder. machine-readable xml document describes content archiveâ€™s data files structure. schema document required file Darwin Core Archive. missing, build_archive() build one. can also build schema document using use_schema(). end process, Darwin Core Archive zip file (dwc-archive.zip). also data-publish folder containing standardised data files (e.g., occurrences.csv), metadata statement EML format (eml.xml), schema document (meta.xml). files can edited time update final Darwin Core Archive.","code":"build_archive(file = \"dwc-archive.zip\")"},{"path":"https://galaxias.ala.org.au/R/articles/quick_start_guide.html","id":"check-archive","dir":"Articles","previous_headings":"","what":"Check archive","title":"Quick start guide","text":"several ways check whether contents Darwin Core Archive meet Darwin Core Standard. first run local tests files inside local folder directory used build Darwin Core Archive. check_directory() allows us check csv files xml files directory Darwin Core Standard criteria. second check whether complete Darwin Core Archive meets institutionâ€™s Darwin Core criteria via API. example, can test archive GBIFâ€™s API tests.","code":"check_directory(\"data-publish\") # Add valid GBIF login details galaxias_config(GBIF = list(email = \"your-email\",                             username = \"your-username\",                             password = \"your-password\"))  # Check against GBIF API check_archive(\"dwc-archive.zip\")"},{"path":"https://galaxias.ala.org.au/R/articles/quick_start_guide.html","id":"publishshare-your-archive","dir":"Articles","previous_headings":"","what":"Publish/share your archive","title":"Quick start guide","text":"final step share completed Darwin Core Archive data infrastructure like Atlas Living Australia. share ALA, can launch data submission process browser calling: function encourage open GitHub Issue can attach archive. run galaxias test suite dataset respond soon can. â€™d prefer use GitHub, can send file brief description support@ala.org.au.","code":"submit_archive()"},{"path":"https://galaxias.ala.org.au/R/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Martin Westgate. Author, maintainer. Shandiya Balasubramaniam. Author. Dax Kellie. Author.","code":""},{"path":"https://galaxias.ala.org.au/R/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Westgate M, Balasubramaniam S, Kellie D (2025). galaxias: Describe, Package, Share Biodiversity Data. R package version 0.1.0, https://galaxias.ala.org.au.","code":"@Manual{,   title = {galaxias: Describe, Package, and Share Biodiversity Data},   author = {Martin Westgate and Shandiya Balasubramaniam and Dax Kellie},   year = {2025},   note = {R package version 0.1.0},   url = {https://galaxias.ala.org.au}, }"},{"path":[]},{"path":"https://galaxias.ala.org.au/R/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Describe, Package, and Share Biodiversity Data","text":"galaxias R package helps users describe, bundle share biodiversity information using â€˜Darwin Coreâ€™ data standard. galaxias provides tools R build Darwin Core Archive, zip file containing standardised data metadata accepted global data infrastructures. package mirrors functionality devtools, usethis dplyr manage data, files folders. galaxias created Science & Decision Support Team Atlas Living Australia (ALA). package named genus freshwater fish found Southern Hemisphere, predominantly Australia New Zealand. logo shows Spotted Galaxias (Galaxias truttaceus) drawn Ian Brennan. comments, questions suggestions, please contact us.","code":""},{"path":"https://galaxias.ala.org.au/R/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Describe, Package, and Share Biodiversity Data","text":"package active development, yet available CRAN. can install latest development version GitHub : Load package:","code":"install.packages(\"remotes\") remotes::install_github(\"atlasoflivingaustralia/galaxias\") library(galaxias)"},{"path":"https://galaxias.ala.org.au/R/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Describe, Package, and Share Biodiversity Data","text":"galaxias contains tools : Standardise save data use_data(). Convert save metadata statements written Rmarkdown Quarto EML files use_metadata(). Build Darwin Core Archives sharing publication using build_archive(). Check files consistency Darwin Core Standard, either locally using check_directory(), via API using check_archive(). galaxias part group packages help users publish data using Darwin Core standard. packages loaded galaxias. packages : corella converting tibbles required column names delma converting markdown files xml","code":""},{"path":"https://galaxias.ala.org.au/R/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Describe, Package, and Share Biodiversity Data","text":"small example dataset species observations. can standardise data according Darwin Core Standard. standardised, can specify wish use standardised data Darwin Core Archive.use_data() saves df_dwc valid csv file name location. Create template metadata statement data. editing, can specify wish use metadata Darwin Core Archive. use_metadata() converts metadata EML format saves valid xml file name location. Build Darwin Core Archive save working directory. Validate whether constructed archive passes Darwin Core Standard criteria. See Quick Start Guide -depth explanation building Darwin Core Archives.","code":"library(tibble)  df <- tibble(   scientificName = c(\"Callocephalon fimbriatum\", \"Eolophus roseicapilla\"),   latitude = c(-35.310, -35.273),    longitude = c(149.125, 149.133),   eventDate = lubridate::dmy(c(\"14-01-2023\", \"15-01-2023\")),   status = c(\"present\", \"present\") )  df #> # A tibble: 2 Ã— 5 #>   scientificName           latitude longitude eventDate  status  #>   <chr>                       <dbl>     <dbl> <date>     <chr>   #> 1 Callocephalon fimbriatum    -35.3      149. 2023-01-14 present #> 2 Eolophus roseicapilla       -35.3      149. 2023-01-15 present df_dwc <- df |>    set_occurrences(occurrenceID = random_id(),                    basisOfRecord = \"humanObservation\",                    occurrenceStatus = status) |>    set_coordinates(decimalLatitude = latitude,                    decimalLongitude = longitude)  df_dwc #> # A tibble: 2 Ã— 7 #>   scientificName          eventDate  basisOfRecord occurrenceID occurrenceStatus #>   <chr>                   <date>     <chr>         <chr>        <chr>            #> 1 Callocephalon fimbriatâ€¦ 2023-01-14 humanObservaâ€¦ 1881b588-36â€¦ present          #> 2 Eolophus roseicapilla   2023-01-15 humanObservaâ€¦ 1881b592-36â€¦ present          #> # â„¹ 2 more variables: decimalLatitude <dbl>, decimalLongitude <dbl> use_data(df_dwc) use_metadata_template(\"metadata.Rmd\") use_metadata(\"metadata.Rmd\") build_archive() check_archive()"},{"path":"https://galaxias.ala.org.au/R/index.html","id":"citing-galaxias","dir":"","previous_headings":"","what":"Citing galaxias","title":"Describe, Package, and Share Biodiversity Data","text":"generate citation package version using, can run: current recommended citation : Westgate MJ, Balasubramaniam S & Kellie D (2025) galaxias: Describe, Package, Share Biodiversity Data. R Package version 0.1.0.","code":"citation(package = \"galaxias\")"},{"path":"https://galaxias.ala.org.au/R/index.html","id":"contributors","dir":"","previous_headings":"","what":"Contributors","title":"Describe, Package, and Share Biodiversity Data","text":"Developers contributed galaxias follows (alphabetical order surname): Amanda Buyan (@acbuyan), Fonti Kar (@fontikar), Peggy Newman (@peggynewman) & Andrew Schwenke (@andrew-1234)","code":""},{"path":"https://galaxias.ala.org.au/R/reference/build_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a Darwin Core Archive from a folder â€” build_archive","title":"Build a Darwin Core Archive from a folder â€” build_archive","text":"Darwin Core archive zip file containing combination data metadata. build_archive() constructs zip file. assumes necessary files pre-constructed, can found inside single folder additional redundant information. source folder file name path archive .zip file set using galaxias_config(). Structurally, build_archive() similar devtools::build(), sense takes repository wraps publication.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/build_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a Darwin Core Archive from a folder â€” build_archive","text":"","code":"build_archive(overwrite = FALSE, quiet = FALSE)"},{"path":"https://galaxias.ala.org.au/R/reference/build_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a Darwin Core Archive from a folder â€” build_archive","text":"overwrite (logical) existing files overwritten? Defaults FALSE. quiet (logical) Whether suppress messages happening. Default set FALSE; .e. messages shown.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/build_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a Darwin Core Archive from a folder â€” build_archive","text":"Invisibly returns location built zip file; typically called side-effect building 'Darwin Core Archive' (.e. zip file).","code":""},{"path":"https://galaxias.ala.org.au/R/reference/build_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build a Darwin Core Archive from a folder â€” build_archive","text":"function looks three types objects specified directory: Data One csv files named occurrences.csv, events.csv /multimedia.csv. csv files contain data standardised using Darwin Core Standard (see corella::corella-package() details). data.frame/tibble can added correct folder using use_data(). Metadata metadata statement EML format file name eml.xml. Completed metadata statements written markdown .Rmd qmd files can converted saved correct folder using use_metadata(). Create new template use_metadata_template(). Schema 'schema' document xml format file name meta.xml. build_archive() detect whether file present build schema file missing. file can also constructed separately using use_schema(). build_archive() build Darwin Core Archive files present source directory. resulting Archive saved zip folder parent directory default.","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/R/reference/build_archive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a Darwin Core Archive from a folder â€” build_archive","text":"","code":"# set up an archive somehow? build_archive() #> â„¹ Building Darwin Core Archive #> â ™ Detecting files... #> âœ” Detecting files... [26ms] #>  #> Error in build_archive(): Directory data-publish does not exist. #> â„¹ See `?galaxias_config()`."},{"path":"https://galaxias.ala.org.au/R/reference/check_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether an archive meets the Darwin Core Standard via API â€” check_archive","title":"Check whether an archive meets the Darwin Core Standard via API â€” check_archive","text":"Check whether specified Darwin Core Archive ready sharing publication, according Darwin Core Standard. check_archive() tests specified archive using online validation service sending archive via API returning results. Currently supports validation using GBIF.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/check_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether an archive meets the Darwin Core Standard via API â€” check_archive","text":"","code":"check_archive(wait = TRUE, quiet = FALSE)  get_report(obj, n = 5, wait = TRUE, quiet = FALSE)  view_report(x, n = 5)  # S3 method for class 'gbif_validator' print(x, ...)"},{"path":"https://galaxias.ala.org.au/R/reference/check_archive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether an archive meets the Darwin Core Standard via API â€” check_archive","text":"wait (logical) Whether wait completed report API exiting (TRUE, default), try API return result regardless (FALSE). quiet (logical) Whether suppress messages happening. Default set FALSE; .e. messages shown. obj Either object class character containing key uniquely identifies query; object class gbif_validator. returned check_archive() get_report() n Maximum number entries print per file. Defaults 5. x object class gbif_validator. ... Additional arguments, currently ignored.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/check_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether an archive meets the Darwin Core Standard via API â€” check_archive","text":"check_archive() get_report() return object class gbif_validator workspace. view_report() print.gbif_validator() return anything, called side-effect printing useful information console.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/check_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check whether an archive meets the Darwin Core Standard via API â€” check_archive","text":"Note file argument check_archive(); instead, location files built checked set using archive argument galaxias_config. Internally, check_archive() POSTs specified archive GBIF validator API calls get_report() retrieve (GET) result. get_report() exported allow user download results later time wish; efficient repeatedly generating queries check_archive() underlying data unchanged. third option simply assign outcome check_archive() get_report() object, call view_report() format result nicely. approach require API calls considerably faster. Note information returned functions provided verbatim institution API, galaxias.","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/R/reference/check_archive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether an archive meets the Darwin Core Standard via API â€” check_archive","text":"","code":"if (FALSE) { # \\dontrun{ # add GBIF login details galaxias_config(gbif = list(username = \"your-gbif-username\",                             email = \"your-gbif-email\",                             password = \"your-gbif-password\"))  # Check archive against Darwin Core Standard criteria check_archive(\"dwc-archive.zip\") } # }"},{"path":"https://galaxias.ala.org.au/R/reference/check_directory.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether contents of directory comply with the Darwin Core Standard â€” check_directory","title":"Check whether contents of directory comply with the Darwin Core Standard â€” check_directory","text":"Checks files directory meet Darwin Core Standard. path directory set directory specified [galaxias_config()]. Users can run galaxias_config() print current specified directory. check_archive() runs corella::check_dataset() occurrences.csv events.csv files, delma::check_metadata() eml.xml meta.xml files, present. check_ functions run tests determine whether data metadata pass Darwin Core Standard criteria.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/check_directory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether contents of directory comply with the Darwin Core Standard â€” check_directory","text":"","code":"check_directory()"},{"path":"https://galaxias.ala.org.au/R/reference/check_directory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether contents of directory comply with the Darwin Core Standard â€” check_directory","text":"Invisibly returns tibble workspace containing check results; primarily called side-effect generating report console.","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/R/reference/check_directory.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether contents of directory comply with the Darwin Core Standard â€” check_directory","text":"","code":"# \\donttest{ # Run checks csv or xml files in specified directory # Defaults to folder data-publish/  check_directory() #> Error in check_directory(): Directory data-publish not found.  # }"},{"path":"https://galaxias.ala.org.au/R/reference/galaxias-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Build repositories to share biodiversity data â€” galaxias-package","title":"Build repositories to share biodiversity data â€” galaxias-package","text":"galaxias helps users describe, package share biodiversity information using 'Darwin Core' data standard, format used accepted Global Biodiversity Information Facility (GBIF) ' partner nodes. galaxias functionally similar devtools, focus building Darwin Core Archives rather R packages. package named genus freshwater fish.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/galaxias-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Build repositories to share biodiversity data â€” galaxias-package","text":"questions, comments suggestions, please email support@ala.org.au. Prepare information Darwin Core use_metadata_template() Add blank metadata statement template working directory suggest_workflow() Advice standardise data using Darwin Core Standard Add information folder use_data() Save standardised data use Darwin Core Archive use_metadata() Convert metadata file markdown EML (eml.xml) save use Darwin Core Archive use_schema() Build schema file (meta.xml) given directory save use Darwin Core Archive Archive management check_directory() Check files local Darwin Core directory build_archive() Convert directory Darwin Core Archive check_archive() Check whether archive passes Darwin Core criteria via GBIF API submit_archive() Open browser submit data ALA Package management galaxias_config() Store credentials API call","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/R/reference/galaxias-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Build repositories to share biodiversity data â€” galaxias-package","text":"Maintainer: Martin Westgate martin.westgate@csiro.au Authors: Shandiya Balasubramaniam shandiya.balasubramaniam@csiro.au Dax Kellie dax.kellie@csiro.au","code":""},{"path":"https://galaxias.ala.org.au/R/reference/galaxias_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Provide configuration information to galaxias â€” galaxias_config","title":"Provide configuration information to galaxias â€” galaxias_config","text":"validate dataset, need provide credentials relevant web service. function allows store information access galaxias API functions. function also enables change directory working documents stored, name archive file resulting zip file placed.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/galaxias_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provide configuration information to galaxias â€” galaxias_config","text":"","code":"galaxias_config(directory = NULL, archive = NULL, gbif = NULL, quiet = FALSE)  # S3 method for class 'galaxias_config' print(x, ...)"},{"path":"https://galaxias.ala.org.au/R/reference/galaxias_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provide configuration information to galaxias â€” galaxias_config","text":"directory Path directory store working files. Defaults data-publish. archive Name zip file completed archive built. Defaults dwc-archive.zip. Note file always saved parent directory per behaviour devtools::build(). gbif (optional) list containing entries username, email password. required intend call check_archive(). quiet (logical) Whether suppress messages happening. Default set FALSE; .e. messages shown. x object class galaxias_config, created galaxias_config(). ... Additional arguments, currently ignored.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/galaxias_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Provide configuration information to galaxias â€” galaxias_config","text":"object class galaxias_config, list containing cached values. galaxias_config() used update (rather view) cache, returned invisibly.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages â€” reexports","title":"Objects exported from other packages â€” reexports","text":"objects imported packages. Follow links see documentation. corella suggest_workflow delma use_metadata_template","code":""},{"path":"https://galaxias.ala.org.au/R/reference/submit_archive.html","id":null,"dir":"Reference","previous_headings":"","what":"Submit a Darwin Core Archive to the ALA â€” submit_archive","title":"Submit a Darwin Core Archive to the ALA â€” submit_archive","text":"preferred method submitting dataset publication via ALA raise issue 'Data Publication' GitHub Repository, attached archive zip file (constructed using build_archive()) issue. dataset especially large (>100MB), need post publicly accessible location (GitHub release) post link instead. function simply opens new issue users' default browser enable dataset submission.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/submit_archive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submit a Darwin Core Archive to the ALA â€” submit_archive","text":"","code":"submit_archive()"},{"path":"https://galaxias.ala.org.au/R/reference/submit_archive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Submit a Darwin Core Archive to the ALA â€” submit_archive","text":"return anything workspace; called side-effect opening submission form users' default browser.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/submit_archive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Submit a Darwin Core Archive to the ALA â€” submit_archive","text":"process accepting data publication ALA automated; function initiate evaluation process, result data instantly visible ALA. submission guarantee acceptance, ALA reserves right refuse publish data reveals locations threatened -risk species.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Use standardised data in a Darwin Core Archive â€” use_data","title":"Use standardised data in a Darwin Core Archive â€” use_data","text":"data conform Darwin Core Standard, use_data() makes easy save data correct place building Darwin Core Archive build_archive(). use_data() --one function accepted data types \"occurrence\", \"event\" \"multimedia\". use_data() attempts detect save correct data type based provided tibble/data.frame. Alternatively, users can call underlying functions use_data_occurrences() use_data_events() specify data type manually.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use standardised data in a Darwin Core Archive â€” use_data","text":"","code":"use_data(..., overwrite = FALSE, quiet = FALSE)  use_data_occurrences(df, overwrite = FALSE, quiet = FALSE)  use_data_events(df, overwrite = FALSE, quiet = FALSE)"},{"path":"https://galaxias.ala.org.au/R/reference/use_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use standardised data in a Darwin Core Archive â€” use_data","text":"... Unquoted name tibble/data.frame save. overwrite default, use_data_events() overwrite existing files. really want , set TRUE. quiet Whether message happening. Default set FALSE. df tibble/data.frame save.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use standardised data in a Darwin Core Archive â€” use_data","text":"Invisibly returns location saved csv file.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use standardised data in a Darwin Core Archive â€” use_data","text":"default, function saves data data-publish folder. change default, see galaxias_config(). Data type determined detecting type-specific column names supplied data. Event: (eventID, parentEventID, eventType) Multimedia: yet supported","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/R/reference/use_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Use a metadata statement in a Darwin Core Archive â€” use_metadata","title":"Use a metadata statement in a Darwin Core Archive â€” use_metadata","text":"metadata statement lists owner dataset, collected, can used (.e. ' licence). function reads converts metadata saved markdown (.md), Rmarkdown (.Rmd) Quarto (.qmd) xml, saves publishing directory. directory set using galaxias_config() defaults \"data-publish\". folder. function convenience wrapper function delma::read_md() delma::write_eml().","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use a metadata statement in a Darwin Core Archive â€” use_metadata","text":"","code":"use_metadata(file = NULL, overwrite = FALSE, quiet = FALSE)"},{"path":"https://galaxias.ala.org.au/R/reference/use_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use a metadata statement in a Darwin Core Archive â€” use_metadata","text":"file metadata file Rmarkdown (.Rmd) Quarto markdown (.qmd) format. overwrite default, use_metadata() overwrite existing files. really want , set TRUE. quiet Whether message happening. Default set FALSE.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use a metadata statement in a Darwin Core Archive â€” use_metadata","text":"return object workspace; called side effect building file data-publish directory.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_metadata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use a metadata statement in a Darwin Core Archive â€” use_metadata","text":"compliant Darwin Core Standard, schema file must called eml.xml, function enforces .","code":""},{"path":[]},{"path":"https://galaxias.ala.org.au/R/reference/use_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use a metadata statement in a Darwin Core Archive â€” use_metadata","text":"","code":"use_metadata_template(quiet = TRUE) use_metadata() #> Error in use_metadata(): Missing `file`, with no default. #> â„¹ Must supply path to existing metadata statement file."},{"path":"https://galaxias.ala.org.au/R/reference/use_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a schema for a Darwin Core Archive â€” use_schema","title":"Create a schema for a Darwin Core Archive â€” use_schema","text":"schema xml document maps files field names DwCA. map makes easier reconstruct one related datasets information matched correctly. works detecting column names csv files specified directory; Darwin Core terms function produce reliable results. publishing directory set using galaxias_config() defaults \"data-publish\".","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a schema for a Darwin Core Archive â€” use_schema","text":"","code":"use_schema(overwrite = FALSE, quiet = FALSE)"},{"path":"https://galaxias.ala.org.au/R/reference/use_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a schema for a Darwin Core Archive â€” use_schema","text":"overwrite default, use_schema() overwrite existing files. really want , set TRUE. quiet (logical) progress messages suppressed? Default set FALSE; .e. messages shown.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a schema for a Darwin Core Archive â€” use_schema","text":"return object workspace; called side effect building schema file publication directory.","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_schema.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a schema for a Darwin Core Archive â€” use_schema","text":"compliant Darwin Core Standard, schema file must called meta.xml, function enforces .","code":""},{"path":"https://galaxias.ala.org.au/R/reference/use_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a schema for a Darwin Core Archive â€” use_schema","text":"","code":"use_schema() #> â„¹ Building schema #> Error in proj_set(\".\"): âœ– Path /tmp/RtmpSXBh1I/ does not appear to be inside a project or #>   package. #> â„¹ Read more in the help for `usethis::proj_get()`."},{"path":"https://galaxias.ala.org.au/R/news/index.html","id":"galaxias-010","dir":"Changelog","previous_headings":"","what":"galaxias 0.1.0","title":"galaxias 0.1.0","text":"First release version. hope like !","code":""}]
